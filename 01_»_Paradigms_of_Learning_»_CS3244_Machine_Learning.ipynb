{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 » Paradigms of Learning » CS3244 Machine Learning",
      "provenance": [],
      "collapsed_sections": [
        "94Gixu7YXa27"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ROHITREDDYBALAM/alpha/blob/master/01_%C2%BB_Paradigms_of_Learning_%C2%BB_CS3244_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvf81x6Vrysn",
        "colab_type": "text"
      },
      "source": [
        "![Machine Learning](https://www.comp.nus.edu.sg/~cs3244/2010/img/CS3244-2010.png)\n",
        "---\n",
        "See **Credits** below for acknowledgements and rights.  For NUS class credit, you'll need to do the corresponding _Assessment_ in [CS3244 in Coursemology](http://coursemology.org/courses/1870) by the respective deadline (mentioned at the end of the notebook). \n",
        "\n",
        "**You must acknowledge that your submitted assessment in Coursemology is your independent work.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy5QuHHir65p",
        "colab_type": "text"
      },
      "source": [
        "# 1 What is Machine Learning?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjFQ5yw1v0pc",
        "colab_type": "text"
      },
      "source": [
        "## Three Examples\n",
        "\n",
        "Let's look at three examples to find out what we mean by ML.  Let's start with an example and use that to define the criteria for what we mean by machine learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ur4X1Xiv30w",
        "colab_type": "text"
      },
      "source": [
        "### What is a Tree?\n",
        "\n",
        "![Supertree](https://www.comp.nus.edu.sg/~cs3244/1910/img/supertree.jpg) \n",
        "\n",
        "_By Erwin Soo from Singapore. (the trees..) [CC BY 2.0](https://creativecommons.org/licenses/by/2.0), via Wikimedia Commons_\n",
        "\n",
        "\n",
        "People know what a tree is.  Normal developed toddlers, just over the age of 2 or 3, can distinguish trees from non-trees by pointing to examples, but without being able to verbalise what they mean by a tree.  Even adults, when faced with the task of defining a tree, generally cannot form the ontological definition found in dictionaries.  But it's clear that a pattern exists: there are leaves on a tree they are branches, and generally there are roots.  We can even understand artificial trees (supertrees at Marina Bay Gardens) or representations of trees (children's drawings of trees; computer science's notion of trees as a data structure) as trees, even though they may not fit the definition.  Thus the second criteria is true; even a textbook definition might not describe all cases of what people understand as \"trees\".   We also have an abundance of examples outside in the real world of what are trees, so there's ample data for it.\n",
        "\n",
        "So to summarise, there are three criteria that describe ML well:\n",
        "1. A pattern exists;\n",
        "2. It's difficult to pin down formally (mathematically);\n",
        "3. We have data for it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gEL917orqQp",
        "colab_type": "text"
      },
      "source": [
        "### The Netflix Prize\n",
        "![Netflix Leaderboard crop](https://www.comp.nus.edu.sg/~cs3244/1910/img/netflix_crop.png)\n",
        "\n",
        "_Screen crop of [The Netflix Leaderboard](https://www.netflixprize.com/leaderboard.html), taken 2019 Aug 2._\n",
        "\n",
        "Another hot area in ML is exemplified by _The Netflix Prize_.  This was a competition held by the company Netflix, to improve its company's algorithm for recommending movies in its service to its customers.  This was formalized by having a system predict a customer's numeric rating of a target movie. The prize was a cool US $1 million for the top performing team that could improve the algorithm, and best its own in-house algorithm by at least 10\\% (and yes, the prize was won by data scientists using machine learning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z37FQpyZglUp",
        "colab_type": "text"
      },
      "source": [
        "_Let's assess ourselves in Coursemology!  Go to [CS3244 in Coursemology](https://coursemology.org/courses/1677) and navigate to the Assessments for Week 1.  Find the `01` assessment and answer these questions in tandem with reading through this notebook.  In future weeks, you should do these **Assessments** while attempting the assignments in the notebook.  Wherever you see the **Your Turn** prompt, it's your turn to do a self-directed exercise._\n",
        "\n",
        "_For programming questions, you should do the programming exercise directly in Colab first, and copy your answer into the relevant Coursemology Assessment so that we can autograde it._\n",
        "\n",
        "_For other multi-choice or textual response questions, you can answer directly in Coursemology.  However, for your own notetaking, you may find it useful to record your answer in the notebook as well._\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMOUjKsnkdUQ",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 1)**:  Perhaps you've heard of this ML application area before.  What do you think this area of ML is called?\n",
        "\n",
        "_Replace with your answer_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_E4PUJWtQG1",
        "colab_type": "text"
      },
      "source": [
        "In this task, previous ratings by a user are assumed to predict (correlate with) future ratings.  That is, the viewer's taste is reflected in her historical ratings and these in turn give imperfect but correlated information about how she will like other, unwatched movies, so _a pattern exists_.  These correlations are hard to pin down formally, because for some people, the genre of a movie is more important, but for others, the actors may be more important, so it's _difficult to pin down formally_.  These preferences (or _weights_) can change person to person, and even within a person's record (i.e., it turns out that weekend movie watching is quite different than weeknight watching).  But importantly, Netflix has plenty of customers and viewing records to help mine these preferences at scale (_we have data_).\n",
        "\n",
        "We can codify the input as two _vectors_, one that encodes the user's preferences, $user\\_pref_v$, and one that encodes the movie's metadata, $movie_v$.  We can then formalize the task as finding matches between these two vectors.  For example, say $user\\_pref_v$ has as its first dimension a Boolean value that indicates whether the user enjoys action movies, say $user\\_pref_t^{(0)}$, and that $movie_v^{(0)}$ also has a Boolean value that indicates whether the movie is an action movie.  Then we might say that the system should predict higher ratings where the corresponding preference in the movie matches than in the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJw3CAjEFHVc",
        "colab_type": "text"
      },
      "source": [
        "### Credit Approval\n",
        "\n",
        "![Netflix Leaderboard crop](https://www.comp.nus.edu.sg/~cs3244/1910/img/credit_card_by_thomas_kohler.png)\n",
        "\n",
        "_Screen crop of Thomas Kohler's [Credit Cards](https://www.flickr.com/photos/mecklenburg/), [CC BY 2.0](https://creativecommons.org/licenses/by/2.0), via Flickr._\n",
        "\n",
        "Banks need to know which loan applicants should be approved for their loan application.  If bank approves an applicant that eventually defaults on their loan, this is a loss for the bank.  Conversely, if they reject an applicant that could actually pay back the loan with the compounded interest, they have missed an opportunity to make money.  The _credit approval problem_ is then to determine from a loan application, whether to approve the application or not.  The inputs are similar to the other scenario, where we have an input application, which we can formalize as an input vector $application_v$, and where the output is a Boolean decision $\\{approve,reject\\}$.  This fits a pattern, but again, where the pattern is hard to exactly formalize.  Banks have plenty of historical records of approval, so it counts as having data to learn a model of decision making from.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IRMxOFHlMa-",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 2)**: Which one of the three criteria is absolutely essential to have for ML to work?\n",
        "\n",
        "_A strong pattern exists, Difficult to pin down formally, We have data_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Iy798UlepV",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 3)**:  What happens when the essential criterion is missing?\n",
        "\n",
        "_Replace with your answer_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLWiikaqBTmR",
        "colab_type": "text"
      },
      "source": [
        "Distilled, here's an example application form that a bank might receive from an applicant.  These constitute the _inputs_ to the credit approval problem. As above, we can view each instance $x$ as an $n$ dimensional vector (i.e., ordered sequences of $n$ values), where the index within the vector gives the value of a specific criterion: e.g. $x_0$ yields \"32\", the applicant's age.\n",
        "\n",
        "| Criterion                  \t| Value   \t|\n",
        "|----------------------------\t|---------\t|\n",
        "| Age                        \t| 32      \t|\n",
        "| Gender                     \t| Male    \t|\n",
        "| Salary (per year)                     \t| 40K     \t|\n",
        "| Debt                       \t| 26K     \t|\n",
        "| Years in Job               \t| 1 Year  \t|\n",
        "| Years at Current Residence \t| 3 Years \t|\n",
        "\n",
        "The above input $x$ could thus be represented as $x = [32,\\ Male,\\ 40K,\\ 26K,\\ 1\\ Year,\\ 3\\ Years]$.  Given an new input $x$ (e.g., a new customer) and a set of historical example inputs with labels, the task in supervised learning is to predict the output label $y$ -- should the bank approve or reject the applicant, i.e., $y \\in \\{approve,\\ reject\\}$.    In supervised learning, a pair of _inputs_ and _output_ constitute an _instance_: $(x,y)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbpAHJKVj1TM",
        "colab_type": "text"
      },
      "source": [
        "## Our notation Part 1: The Data Matrix "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En-iunUCDG7Z",
        "colab_type": "text"
      },
      "source": [
        "When we have more than one input and label, we can compile a _data matrix_ as a representation of the entire dataset.  It is a rectangular matrix  that stacks all of the input instances (a.k.a. _observations_, _samples_) represented by rows of _features_  in a matrix.  Note that when we do this, by tradition, we transpose the instance vectors to form rows (recall that from linear algebra that \"vectors\" without qualification are column vectors).\n",
        "\n",
        "When there are known outputs (a.k.a., _targets_, _answers_, _ground truth_, _labels_) for the instances, we can append that column of outputs.  Slightly redefining the previous paragraph for the more usual data matrix context, we'll refer to the entire set of _inputs_ as $\\mathbf{X}$ and the entire column of outputs as $\\mathbf{y}$ (as opposed to using the variables for individual instances).  To refer to individual instances, we need to give give an index to which instance we want to refer to, as in $(\\mathbf{x}^{(j)},y^{(j)})$ to refer to the specific $j$th instance (row) in the data matrix.  \n",
        "\n",
        "As Andrew Ng's Coursera and Stanford classes are quite popular and the math notation quite good, we'll follow their notation of math variables where possible (there may be occasional errors -- please let us know where you see them).  Do be aware that there is lots and lots of variation in math notation for ML, this is partially because this is an interdisciplinary field itself:\n",
        "\n",
        "\n",
        "| Notation                  \t| Meaning   \t|\n",
        "|----------------------------\t|---------\t|\n",
        "| $\\mathbf{x}$                | an input example (vector) |\n",
        "| $\\mathbf{X}$                | a stacked set of inputs of form $\\mathbf{x}$ |\n",
        "| $\\mathbf{y}$                | set of (aligned) outputs \t|\n",
        "| $n$                     \t  | number of features \t|\n",
        "| $m$                     \t  | number of samples\t|\n",
        "|$\\mathbf{x}_i$| $i^{th}$ feature of input $\\mathbf{x}$ |\n",
        "|$\\mathbf{x}^{(j)}$|$j^{th}$ input or instance |\n",
        "\n",
        "Just to be clear, the superscript in $\\mathbf{x}^{(j)}$ indicates an index into the $\\mathbf{X}$ matrix to pull out the $j$th instance, it has nothing to do with exponentiation (hence the added parentheses to differentiate its usage); the data matrix is an $m\\times n$ matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UFdiJxTx4RG",
        "colab_type": "text"
      },
      "source": [
        "## Our Notation Part 2: Components of ML\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqSRUSiTN2tK",
        "colab_type": "text"
      },
      "source": [
        "We will also use $\\mathcal{X}$ denote the space of input values, and $\\mathcal{Y}$ to denote the space of output values.  \n",
        "\n",
        "Let's denote the underlying, real target function as $f$.  $f$ is unknown to us, except through the instances provided in training.  The learner's job is to approximate the full function $f$ (that is, $f$ over $\\mathcal{X}$) as best as it can, based on the examples $\\mathbf{X}$, where we know the actual values of $f(\\mathbf{x}) \\rightarrow y$.  \n",
        "\n",
        "Thus, the goal in supervised machine learning is to learn a function $h:\\mathcal{X} \\rightarrow \\mathcal{Y}$.  Invoking $h(x)$ on a test input $\\mathbf{x}$ should hopefully yield a value close to the target value $y$.  We use the letter $h$ to denote this learned function, as it is termed a _hypothesis_.   \n",
        "You may also see notation for \"learned\" output of the function and target value as $\\hat{f}$ and $\\hat{y}$ as the \"hat\" is used to the algorithmic approximation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFYYxx47pewU",
        "colab_type": "text"
      },
      "source": [
        "There are different _learning algorithms_ that can be utilised to learn an approximation to $f$.  Algorithms may represent $h$ differently, and hence the space of possible hypotheses $\\mathcal{H}=\\{h_1,h_2,...,h_{|\\mathcal{H}|}\\}$ for it to choose from to find the best $h$ to approximate $f$ for learners may be different.  \n",
        "\n",
        "Often, a classifier has parameters which it can set to best represent the function $f$. For example, a linear classifier (which we'll try in Week 4) is limited to hypotheses that represent lines (hyperplanes in high dimensional space).  A particular setting of these parameters $\\theta$ chooses among the elements in $\\mathcal{H}$, and is the _model representation_ of the algorithm for the data.  In the linear classifier case, the $\\theta$ (also variously $\\mathbf{w}$ for _weights_) are the model parameters (here, scaling coefficients for the $n$ individual features $\\mathbf{x}_{1...n}$) of the linear combination.  Don't worry too much if you don't follow this yet.\n",
        "\n",
        "Running the algorithm finds a hopefully optimal $\\theta$ to best match the pattern of $h_\\theta(\\mathbf{x}^{(i)}) \\rightarrow y^{(i)}$ for all $i$ in the training data.  We choose the machine learning algorithm $\\mathcal{A}$, and the algorithm chooses $h_\\theta$ as its best approximation to $f$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q41sH-S9sIBX",
        "colab_type": "text"
      },
      "source": [
        "# 2 Paradigms of ML\n",
        "\n",
        "When a pattern exists, and a straightforward definition is not easy to come by and we have sufficient access to data, we can use ML.  Generally, there are three paradigms of ML: \n",
        "\n",
        "* Supervised\n",
        "* Unsupervised\n",
        "* Reinforcement\n",
        "\n",
        "They differ in the types of feedback that the learner receives on its outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UATxcaIRtMV_",
        "colab_type": "text"
      },
      "source": [
        "## .a Supervised Learning\n",
        "\n",
        "\n",
        "Cat: ![Cat](https://www.comp.nus.edu.sg/~cs3244/1910/img/cat.jpg)\n",
        "Dog: ![Dog](https://www.comp.nus.edu.sg/~cs3244/1910/img/dog.jpg)\n",
        "\n",
        "_Photo of cat by [Vladimir Pustovit](https://www.flickr.com/photos/pustovit/); photo of dog by [Michal Ščuglík](https://www.flickr.com/photos/scuglik).  Both [CC BY 2.0](https://creativecommons.org/licenses/by/2.0), via Flickr._\n",
        "\n",
        "In **[supervised](https://en.wikipedia.org/wiki/Supervised_learning)** learning, for each input instance, there is a corresponding _answer_ (a.k.a. _label_).  For example, an image dataset can provide _labels_ of what is in the main subject in the image: a _dog_ or a _cat_.  This subject will make up the bulk of our course, from Weeks 02-10.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYr4AYwCm1Ek",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 4)**: Give a short description (1 paragraph; 1-4 sentences) of a problem that would fit the supervised paradigm of machine learning. Explain why it fits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7yaoAZcMJ-U",
        "colab_type": "text"
      },
      "source": [
        "Interestingly, when people discuss **deep learning** they are usually referring to recent progress in the supervised paradigm using multilayer neural networks. We'll cover this interesting development in Weeks 08-09, although some of you may want to investigate this topic earlier for your projects.  Much of deep learning is actually mathematically simpler than much of the formal parts of ML, and if you have a good background in linear algebra, you can \"catch up\" with deep learning quite readily (as compared to traditional ML as in our class, which requires more mathematical rigor).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZS3egoTg_FO",
        "colab_type": "text"
      },
      "source": [
        "Now let's actually try to get some time on task in class.  Let's execute supervised learning.  We'll follow a modified tutorial for **[sklearn](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)**, a very useful Python machine learning library.  Let's first get the dataset _digits_ loaded in and take a peek at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "859DSq97g_a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the libraries to access data \n",
        "from sklearn import datasets\n",
        "\n",
        "# load in the data into a variable 'digits'\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# separate the loaded data into the feature vectors x and their corresponding labels y\n",
        "x_digits = digits.data\n",
        "y_digits = digits.target\n",
        "\n",
        "# find the number of instances in our dataset\n",
        "n_samples = len(x_digits)\n",
        "print ('Number of examples: %d' % n_samples)\n",
        "\n",
        "# Look at the input (x) and label (y) for a particular jth instance\n",
        "j = 0\n",
        "print ('Input #%d:' % j, x_digits[j])\n",
        "print ('Label #%d:' % j, y_digits[j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUJq0r75g-cW",
        "colab_type": "text"
      },
      "source": [
        "This particular dataset are handwritten digits and represented by $8\\times8 = 64$ entries, all strung up in a 1-dimension vector.   See whether you can make sense of the data.  Next, we'll split the data instances into those used to learn the model (training instances), and those used to assess the learned model's performance (testing instances)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZrjhimNnUn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set aside the first 90% of the data for the training and the remaining 10% for testing.\n",
        "x_train = x_digits[0:int(.9 * n_samples)]\n",
        "y_train = y_digits[0:int(.9 * n_samples)]\n",
        "x_test = x_digits[int(.9 * n_samples):]\n",
        "y_test = y_digits[int(.9 * n_samples):]\n",
        "print ('Number of training examples: %d' % len(y_train))\n",
        "print ('Number of testing examples: %d' % len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-50heK_nIYA",
        "colab_type": "text"
      },
      "source": [
        "**Extra tipp**:  In this example we just split the data by ourselves and used the last 10% for testing. In most cases it is better to use a random split, [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) is a function that you can use for random splits in sklearn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6DWrK42g-a3",
        "colab_type": "text"
      },
      "source": [
        "Finally we'll do model learning and assessing.  Although it's the core of what we are learning in this course, in `sklearn`, it's a few (actually just 1, in the original tutorial) lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQGvSIpRp9l8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the library to use our desired classifier (here, nearest neighbors, we'll see it next week) \n",
        "from sklearn import neighbors\n",
        "\n",
        "# create an instance of the learner\n",
        "knn = neighbors.KNeighborsClassifier()\n",
        "\n",
        "# learn an h from the training data \n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "# evaluate h over the testing data and print its accuracy.  We'll save its performance to show we did some work in class!\n",
        "Q05 = knn.score(x_test,y_test)             \n",
        "print('KNN score: %f' % Q05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBsNzyHjqK-z",
        "colab_type": "text"
      },
      "source": [
        "That was pretty easy, wasn't it?  Congratulations on finishing your first programming assignment in Colab!\n",
        "\n",
        "**Your Turn (Question 5)** Paste your kNN classifier's score result into the assessment cell (copy paste the printed number exactly)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCIWsEcku7cs",
        "colab_type": "text"
      },
      "source": [
        "## .b Unsupervised Learning\n",
        "??: ![Cat](https://www.comp.nus.edu.sg/~cs3244/1910/img/cat.jpg)\n",
        "??: ![Dog](https://www.comp.nus.edu.sg/~cs3244/1910/img/dog.jpg)\n",
        "\n",
        "When input instances do not come with a _label_, we say the problem is **[unsupervised](https://en.wikipedia.org/wiki/Unsupervised_learning)**.  That is, our data set that we wish to learn from just has a set of instances that have just a feature vector, with no corresponding label.  But what can you do when you don't have an answer to learn from?  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS0Hk1Uonn0w",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 6)**: What can we do with such unlabeled data?  Give a short sentence describing one task that could be accomplished using data without labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT0vgQeTJTHf",
        "colab_type": "text"
      },
      "source": [
        "Learning without labels is an important form of learning, and has several different applications.  A downside of unsupervised learning is that there is no straightforward way of assessing the quality of the outcome (as there are no answers provided).  \n",
        "\n",
        "Due to our limited time schedule, we have little time to cover this topic.  We'll touch on the core aspect of unsupervised learning in one week towards the end of the course (Week 11). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94Gixu7YXa27",
        "colab_type": "text"
      },
      "source": [
        "### Applications of Unsupervised Learning (don't expand until you've answered Question 6 yourself)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evl5k-lxYxDR",
        "colab_type": "text"
      },
      "source": [
        "We'll be covering the application of _clustering_, the grouping of instances into clusters, during Week 11.  Often times, the number of clusters is pre-specified by the analyst, but this is a parameter that can also be learned.  \n",
        "\n",
        "Other applications of unsupervised learning can include _density estimation_, a key problem common in statistics.  Here a dataset is assumed to be representative of a larger population, and the goal is to estimate the probability of data, leveraging known or inferred conditional dependencies.  For example, determining the probability of myopia in populations with certain features (race, gender, age, average hours of sleep).  \n",
        "\n",
        "Unsupervised learning of both sorts (clustering or density estimation) also yields another application of _outlier detection_.  Outliers are instances in the dataset that are uncharacteristic of the datatset (i.e., far away from cluster centers), and sometimes are filtered out as noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahVw7Najv74I",
        "colab_type": "text"
      },
      "source": [
        "## .c Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkauYKtNMUA8",
        "colab_type": "text"
      },
      "source": [
        "Equally exciting to those exploring ML is the area of **[reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning)** (RL), where problem instances do not have labels, but instead are arrayed in a series of states that yield a reward (or penalty).  Each part of the sequence in RL can be thought of as containing two logical parts: a _state_ and an _action_.  For example, a robot drone may have detectors that give rise to a representation of its _state_ (e.g., onboard clock, GPS, touch sensors, 360º camera, LIDAR), and can decide to take some _action_ (e.g., slow down, turn right).  A key part of RL is the _reward function_, which encodes the designer's thinking about how the agent's actions were useful in accomplishing its ultimate goal (e.g., delivering a package).  While each instance can be associated with a reward, rewards are not labels as they do not characterise the instance.  Instances in RL often form a chronological sequence: an agent changes its state using an action, then evaluates the reward function for its action to form a new instance as part of a sequence.  A _policy_ $\\pi$ outlines the agent's selection of actions given a state, and often is modeled probabilistically.\n",
        "\n",
        "Applications of RL include many scheduling / logistics problems as well as agent planning problems (i.e., robot navigation). \n",
        "\n",
        "When the popular press discusses programs that can learn for itself, many times it is referring to this area.  Some forms of game playing (notably Google's _AlphaGo_, and OpenAI5 for DoTA) and the deep learning area of _Generative Adversarial Networks_ (GANs), which popularly do stylistic transfer from artwork onto images or are used to create _deepfakes_, fall under this category.  We'll touch upon reinforcement and adversarial learning in Week 07.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZX4JTdyIRuQ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# Post-Tutorial Work\n",
        "\n",
        "Each week you will be required to watch videos through [CS3244 in Coursemology](http://www.comp.nus.edu.sg/~cs3244/2010/01.videos.html)'s _Videos_:\n",
        "\n",
        "1. before the tutorial timing (even though it is flipped), to introduce you to the concepts to be discussed during class; and \n",
        "2. after the tutorial timing, for reinforcing concepts shown in class;\n",
        "\n",
        "Pedagogical studies have shown that preparation and reinforcement are key aspects of mastery learning and hence we are following this model in our flipped classroom design.\n",
        "\n",
        "As this is the first week of class, we won't be reviewing any particular content.  You will have to watch the post-tutorial videos on this class' administrivia for course organization  and project\n",
        " and watch the following video that expands on the concepts in this notebook.\n",
        "\n",
        "Pedro Domingo's *Five Tribes of Machine Learning* @ Talks at Google (approx 1 hr).  \n",
        "\n",
        "(please watch and discuss on Coursemology's [video component](http://www.comp.nus.edu.sg/~cs3244/2010/01.videos.html))\n",
        "\n",
        "After watching all of the videos, please answer the following questions in the _W1 Post_ Assessment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA2L2uznqh54",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 1)**: Name one of the two class rules that CS 3244 employs on top of the NUS Academic Honesty Policy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNGPoCGTuK23",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 2)**: What happens to your class grade if you are found cheating or plagiarising?\n",
        "\n",
        "Write a sentence describing the consequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sBO6rgquT2L",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 3)**: What do analogizers believe in?\n",
        "\n",
        "Write a sentence to encapsulate what Pedro means by an analogizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BYg0DXDuePb",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 4)**: Based on your preliminary understanding of the syllabus at http://www.comp.nus.edu.sg/~cs3244 , name any one of the five tribes of ML that will be represented in our course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFAcK2oPvHCF",
        "colab_type": "text"
      },
      "source": [
        "**Your Turn (Question 5)**: Are recommendation systems as we formalized in the Netflix example above an analogy (i.e., due to the Analogizers)?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019c6M1rK4gs",
        "colab_type": "text"
      },
      "source": [
        "*N.B.: Pedro is a master machine learning expert with the University of Washington, and author of the self-same book.  We think it's a great book to learn more about the history and personalities in the field of machine learning and also to introduce you to Markov Logic Networks, an advanced form of ML we won't cover in this course.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fJ3EPCnkrPNw"
      },
      "source": [
        "# Credits\n",
        "Authored by [Min-Yen Kan](http://www.comp.nus.edu.sg/~kanmy), Chris Boesch and Martin Strobel (2018, 2020), affiliated with [WING](http://wing.comp.nus.edu.sg), [NUS School of Computing](http://www.comp.nus.edu.sg) and [ALSET](http://www.nus.edu.sg/alset). Inspired in part by Andrew Ng's Coursera course and Yaser S. Abu-Mostafa's Caltech course.\n",
        "Licensed as: [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/ ) (CC BY 4.0).\n",
        "Please retain and add to this credits cell if using this material as a whole or in part.   Credits for photos given in their captions."
      ]
    }
  ]
}